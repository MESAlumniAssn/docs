{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The MES College Alumni Association \u00ae Greetings and welcome to the documentation site for mesalumniassociation.com . Before diving deep into technical details, please read further to understand the objectives and goals of the project from an operational and a technology standpoint. Goals Keep the operational costs low Continuous Documentation Keeping the costs low The primary consideration while determining the current website/API architecture was the overall cost. Most pages on the website built for the initial launch are static. The registration/post-registration pages are few exceptions since they connect to a data store. As a result, the website, the database and the backend API are all deployed on a basic virtual private server (VPS) with 1GB of RAM and a 25GB SSD disk. The VPS owned by DigitalOcean , resides in their BLR data centre. The association has been made aware that as the scope of the website increases, the infrastructure will need to be scaled up. Keeping costs in mind, the project uses free/basic tiers of various external cloud based services. For CI/CD, the project uses the free tier of Travis CI Images are served from the free tier of ImageKit For emails, the project is using the Essentials 40K paln from SendGrid Github is the repository for the source code At the moment, the free tier's will suffice. However, if at any time, the scope of the project is deemed to go beyond the allowed limit of any of the free tier's, it needs to be brought to the attention of the association so that an appropriate decision can be taken. Continuous Documentation Presently, the association does not have a dedicated technical team for this project. All technical tasks (including this documentation) have been carried out by an alumni. Until there is a dedicated team, upcoming work will most likely be assigned to other interested alumni or freelancers. It is therefore imperative that any new or changing features are accurately documented so that there is a smooth handover to new project personnel. What this documentation is A guide to set up all the projects A means to understand all the project and user workflows What this documentation is not A tutorial for the different languages and frameworks used in the project A detailed code walk-through Technology Stack Frontend Backend Database Other Tools and Services","title":"Home"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#goals","text":"Keep the operational costs low Continuous Documentation","title":"Goals"},{"location":"#keeping-the-costs-low","text":"The primary consideration while determining the current website/API architecture was the overall cost. Most pages on the website built for the initial launch are static. The registration/post-registration pages are few exceptions since they connect to a data store. As a result, the website, the database and the backend API are all deployed on a basic virtual private server (VPS) with 1GB of RAM and a 25GB SSD disk. The VPS owned by DigitalOcean , resides in their BLR data centre. The association has been made aware that as the scope of the website increases, the infrastructure will need to be scaled up. Keeping costs in mind, the project uses free/basic tiers of various external cloud based services. For CI/CD, the project uses the free tier of Travis CI Images are served from the free tier of ImageKit For emails, the project is using the Essentials 40K paln from SendGrid Github is the repository for the source code At the moment, the free tier's will suffice. However, if at any time, the scope of the project is deemed to go beyond the allowed limit of any of the free tier's, it needs to be brought to the attention of the association so that an appropriate decision can be taken.","title":"Keeping the costs low"},{"location":"#continuous-documentation","text":"Presently, the association does not have a dedicated technical team for this project. All technical tasks (including this documentation) have been carried out by an alumni. Until there is a dedicated team, upcoming work will most likely be assigned to other interested alumni or freelancers. It is therefore imperative that any new or changing features are accurately documented so that there is a smooth handover to new project personnel.","title":"Continuous Documentation"},{"location":"#what-this-documentation-is","text":"A guide to set up all the projects A means to understand all the project and user workflows","title":"What this documentation is"},{"location":"#what-this-documentation-is-not","text":"A tutorial for the different languages and frameworks used in the project A detailed code walk-through","title":"What this documentation is not"},{"location":"#technology-stack","text":"","title":"Technology Stack"},{"location":"#frontend","text":"","title":"Frontend"},{"location":"#backend","text":"","title":"Backend"},{"location":"#database","text":"","title":"Database"},{"location":"#other-tools-and-services","text":"","title":"Other Tools and Services"},{"location":"architecture/","text":"Application Architecture The website sits behind Cloudflare which acts as the content delivery network (CDN). We are using the free tier of the CDN as the current iteration of the website does not warrant an upgrade to a paid tier. The CDN largely helps in improving the performance by serving the website from Cloudflare's 200 plus PoP's (points of presence). It also serves as a caching layer for static assets. We use a single DigitalOcean droplet running Ubuntu 20.04 LTS which hosts the website, the backend api and the database. The website is developed in Next.js . The backend api endpoints, built with FastAPI talk to a PostgreSQL database. ImageKit.io is our image store. In addition to storing images, we also use ImageKit's transformations while fetching images. All payments are processed via Razorpay 's api and emails to end users/the association are sent from SendGrid . Editing the architecture diagram The diagram was created with draw.io . To edit the image, open the architecture.drawio.png file included in the docs repository on the draw.io website or download the Draw.io Integration plugin for VS Code and open the file in the VS Code editor itself. The architecture diagram is stored in the Docs directory on the project's ImageKit.io account.","title":"Architecture"},{"location":"architecture/#application-architecture","text":"The website sits behind Cloudflare which acts as the content delivery network (CDN). We are using the free tier of the CDN as the current iteration of the website does not warrant an upgrade to a paid tier. The CDN largely helps in improving the performance by serving the website from Cloudflare's 200 plus PoP's (points of presence). It also serves as a caching layer for static assets. We use a single DigitalOcean droplet running Ubuntu 20.04 LTS which hosts the website, the backend api and the database. The website is developed in Next.js . The backend api endpoints, built with FastAPI talk to a PostgreSQL database. ImageKit.io is our image store. In addition to storing images, we also use ImageKit's transformations while fetching images. All payments are processed via Razorpay 's api and emails to end users/the association are sent from SendGrid .","title":"Application Architecture"},{"location":"architecture/#editing-the-architecture-diagram","text":"The diagram was created with draw.io . To edit the image, open the architecture.drawio.png file included in the docs repository on the draw.io website or download the Draw.io Integration plugin for VS Code and open the file in the VS Code editor itself. The architecture diagram is stored in the Docs directory on the project's ImageKit.io account.","title":"Editing the architecture diagram"},{"location":"documentation/","text":"Updating the documentation The documentation site uses Material for MKDocs . All the pages are written in Markdown with few sprinkles of HTML and CSS. The documentation site is hosted on Github Pages. The configuration file, ci.yml is located in .github/workflows in the docs repository. Once a change is pushed to the main branch, the workflow automatically kicks off and deploys the site on Github Pages. Presently, all changes are being pushed directly to the main branch. It is up to the developers, if they would like to create a feature branch and merge the changes to main .","title":"Documentation Changes"},{"location":"documentation/#updating-the-documentation","text":"The documentation site uses Material for MKDocs . All the pages are written in Markdown with few sprinkles of HTML and CSS. The documentation site is hosted on Github Pages. The configuration file, ci.yml is located in .github/workflows in the docs repository. Once a change is pushed to the main branch, the workflow automatically kicks off and deploys the site on Github Pages. Presently, all changes are being pushed directly to the main branch. It is up to the developers, if they would like to create a feature branch and merge the changes to main .","title":"Updating the documentation"},{"location":"setup/","text":"Setting up the projects Following github repositories under the MESAlumniAssn user contain all the projects - mes-aa-site - the Next.js/React website mes-aa-api - the Python based api mes-aa-jobs - the helper jobs running on the server docs - the documentation site Install dependencies Python v3.8 Node.js v14.17.6 or higher Setting up the mes-aa-api project locally Clone the repository - git clone https://github.com/MESAlumniAssn/mes-aa-api Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Create the environment variables in a .env file. Refer to the .env.example file for the list of variables Run the project - uvicorn app.main:app --reload This project should be run before starting the website ( mes-aa-site ) The requirements.txt on the server contains additional dependencies like gunicorn which are not needed locally to run the project in the present setup Setting up the mes-aa-site project locally Clone the repository - https://github.com/MESAlumniAssn/mes-aa-site Install the project dependencies - npm i Create the environment variables in a .env.local file. Refer to the .env.local.example file for the lit of variables Run the project - npm run dev Setting up the mes-aa-jobs project locally Clone the repository - https://github.com/MESAlumniAssn/mes-aa-jobs Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Create the environment variables in a .env file. Refer to the .env.example file for the list of variables Run a specific job - Birthday notifications - python birthday.py Membership expiry notifications - python expiry_notifications.py Renewal notifications - python renewal_notifications.py Setting up the docs project locally Clone the repository - https://github.com/MESAlumniAssn/mes-aa-jobs Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Run the project - mk docs serve","title":"Project Setup"},{"location":"setup/#setting-up-the-projects","text":"Following github repositories under the MESAlumniAssn user contain all the projects - mes-aa-site - the Next.js/React website mes-aa-api - the Python based api mes-aa-jobs - the helper jobs running on the server docs - the documentation site","title":"Setting up the projects"},{"location":"setup/#install-dependencies","text":"Python v3.8 Node.js v14.17.6 or higher","title":"Install dependencies"},{"location":"setup/#setting-up-the-mes-aa-api-project-locally","text":"Clone the repository - git clone https://github.com/MESAlumniAssn/mes-aa-api Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Create the environment variables in a .env file. Refer to the .env.example file for the list of variables Run the project - uvicorn app.main:app --reload This project should be run before starting the website ( mes-aa-site ) The requirements.txt on the server contains additional dependencies like gunicorn which are not needed locally to run the project in the present setup","title":"Setting up the mes-aa-api project locally"},{"location":"setup/#setting-up-the-mes-aa-site-project-locally","text":"Clone the repository - https://github.com/MESAlumniAssn/mes-aa-site Install the project dependencies - npm i Create the environment variables in a .env.local file. Refer to the .env.local.example file for the lit of variables Run the project - npm run dev","title":"Setting up the mes-aa-site project locally"},{"location":"setup/#setting-up-the-mes-aa-jobs-project-locally","text":"Clone the repository - https://github.com/MESAlumniAssn/mes-aa-jobs Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Create the environment variables in a .env file. Refer to the .env.example file for the list of variables Run a specific job - Birthday notifications - python birthday.py Membership expiry notifications - python expiry_notifications.py Renewal notifications - python renewal_notifications.py","title":"Setting up the mes-aa-jobs project locally"},{"location":"setup/#setting-up-the-docs-project-locally","text":"Clone the repository - https://github.com/MESAlumniAssn/mes-aa-jobs Create a virtual environment - python -m venv venv Activate the virtual environment - venv\\Scripts\\activate (windows) or source venv/bin/activate (Linux/MacOS) Install the project dependencies - pip install -r requirements.txt Run the project - mk docs serve","title":"Setting up the docs project locally"},{"location":"workflow/","text":"Developer Workflow Until the site went live, all changes were checked directly into the main branch of the respective projects. Now that we are live, following is the recommended approach for making changes in the site , api and jobs projects. Changes to docs can be pushed directly to the main branch. The below processes do not apply to the docs project. See documentation changes for details to update the project documentation. Getting access It is preferred that developers use their personal Github accounts and request for access to all the repos under MESAlumniAssn . All passwords are stored in a LastPass... vault. The developers who require access to any specific service, should contact the association for specific passwords. Github workflow Whenever there is a new feature request or a potential bug fix, the first step is to open an issue in Github using the pre-configured template. The new feature template exists only in the mes-aa-site repository where as all the projects contain the bug fix template. Next, create a local branch - git checkout -b <branch_name> The naming convention for branches should be as follows - Bug fix - mes-aa-bug-issue_number Ex: mes-aa-bug-#10 New feature - mes-aa-feature-issue_number Ex: mes-aa-feature-#11 Composite (includes both a bux fix and new feature) - mes-aa-hybrid-issue_number_1-issue_number_2 Ex: mes-aa-hybrid-#12-#13 Once the changes are complete and tested, commit the changes and push the changes to the remote repo - git push origin <branch_name> . Next, create a pull request, check for merge conflicts (if any) and merge the changes with the main branch and close the pull request. This will automatically close the issue as well. The CI/CD pipeline Once the changes are merged with main , the CI/CD pipeline kicks off on Travis CI (the Build pushed branches option is checked for all the repo's on Travis CI). Each project includes a travis.yml file with the build configuration. At the moment, tests are only included for the mes-aa-site repository. These tests were added merely to serve as a smoke test prior to deployment. There is an opportunity to add tests for the api and jobs projects as well. During the initial phase of the project, the developer received continuous feedback from the website committee. Due to this, the addition of tests was low on the priority list. This needs to be eventually addressed. The final step of the build, executes a shell script, deploy.sh . This deploys the code from the latest build on the server. The Python api backend uses gunicorn which is run as a daemon process using the supervisor package. Once any change is deployed for the api project, supervisor must be restarted when logged in as the sudo user on the server, using the command sudo supervisorctl reload No separate restarts are needed for the site project. This is automatically handled in the deploy.sh script. For details on the pipeline and server setup, please refer to these articles Initial setup on a Linux server Deploying a Python application - the article walks through a Flask app but the steps are same Deploying a react application Setting up the CD/Cd pipeline","title":"Developer Workflow"},{"location":"workflow/#developer-workflow","text":"Until the site went live, all changes were checked directly into the main branch of the respective projects. Now that we are live, following is the recommended approach for making changes in the site , api and jobs projects. Changes to docs can be pushed directly to the main branch. The below processes do not apply to the docs project. See documentation changes for details to update the project documentation.","title":"Developer Workflow"},{"location":"workflow/#getting-access","text":"It is preferred that developers use their personal Github accounts and request for access to all the repos under MESAlumniAssn . All passwords are stored in a LastPass... vault. The developers who require access to any specific service, should contact the association for specific passwords.","title":"Getting access"},{"location":"workflow/#github-workflow","text":"Whenever there is a new feature request or a potential bug fix, the first step is to open an issue in Github using the pre-configured template. The new feature template exists only in the mes-aa-site repository where as all the projects contain the bug fix template. Next, create a local branch - git checkout -b <branch_name> The naming convention for branches should be as follows - Bug fix - mes-aa-bug-issue_number Ex: mes-aa-bug-#10 New feature - mes-aa-feature-issue_number Ex: mes-aa-feature-#11 Composite (includes both a bux fix and new feature) - mes-aa-hybrid-issue_number_1-issue_number_2 Ex: mes-aa-hybrid-#12-#13 Once the changes are complete and tested, commit the changes and push the changes to the remote repo - git push origin <branch_name> . Next, create a pull request, check for merge conflicts (if any) and merge the changes with the main branch and close the pull request. This will automatically close the issue as well.","title":"Github workflow"},{"location":"workflow/#the-cicd-pipeline","text":"Once the changes are merged with main , the CI/CD pipeline kicks off on Travis CI (the Build pushed branches option is checked for all the repo's on Travis CI). Each project includes a travis.yml file with the build configuration. At the moment, tests are only included for the mes-aa-site repository. These tests were added merely to serve as a smoke test prior to deployment. There is an opportunity to add tests for the api and jobs projects as well. During the initial phase of the project, the developer received continuous feedback from the website committee. Due to this, the addition of tests was low on the priority list. This needs to be eventually addressed. The final step of the build, executes a shell script, deploy.sh . This deploys the code from the latest build on the server. The Python api backend uses gunicorn which is run as a daemon process using the supervisor package. Once any change is deployed for the api project, supervisor must be restarted when logged in as the sudo user on the server, using the command sudo supervisorctl reload No separate restarts are needed for the site project. This is automatically handled in the deploy.sh script. For details on the pipeline and server setup, please refer to these articles Initial setup on a Linux server Deploying a Python application - the article walks through a Flask app but the steps are same Deploying a react application Setting up the CD/Cd pipeline","title":"The CI/CD pipeline"}]}